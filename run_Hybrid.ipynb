{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import yaml\n",
    "from hy2dl.modelzoo import get_model\n",
    "from hy2dl.modelzoo.baseconceptualmodel import BaseConceptualModel\n",
    "from hy2dl.utils.config import Config\n",
    "from hy2dl.utils.utils import set_random_seed\n",
    "from utilities.data import DataHandler\n",
    "from utilities.postprocessing import Postprocessor\n",
    "from utilities.training import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663a778",
   "metadata": {},
   "source": [
    "### Part 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c27936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = yaml.safe_load(open(\"files/camels_gb.yml\"))\n",
    "\n",
    "# Modify configuration\n",
    "config[\"experiment_name\"] = \"CAMELS-GB_Hybrid-Custom-Model_NSE\"\n",
    "config[\"path_save_folder\"] = \"results/run_Hybrid\"\n",
    "config[\"model\"] = \"hybrid\"\n",
    "config[\"conceptual_model\"] = \"shm\"\n",
    "config[\"dynamic_parameterization_conceptual_model\"] = [\n",
    "    \"dd\", \"f_thr\", \"sumax\", \"beta\", \"perc\", \"kf\", \"ki\", \"kb\"\n",
    "]\n",
    "\n",
    "# Convert into 'Config' object\n",
    "config = Config(config)\n",
    "config.init_experiment()\n",
    "config.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d38dc6",
   "metadata": {},
   "source": [
    "### Part 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68921c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "handler_data = DataHandler(config)\n",
    "handler_data.load_data()\n",
    "\n",
    "basin_ids = handler_data.get_basin_ids()\n",
    "\n",
    "loader_training = handler_data.get_loader(\"training\")\n",
    "loader_validation = handler_data.get_loader(\"validation\")\n",
    "dataloaders = {\n",
    "    \"training\": loader_training,\n",
    "    \"validation\": loader_validation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af18420",
   "metadata": {},
   "source": [
    "### Part 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "set_random_seed(cfg=config)\n",
    "model = get_model(config).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check conceptual model parameter ranges and types\n",
    "print(model.conceptual_model.parameter_ranges)\n",
    "print(model.conceptual_model.parameter_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa4701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(BaseConceptualModel):\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super(my_model, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.n_conceptual_models = cfg.num_conceptual_models\n",
    "        self.parameter_type = self._map_parameter_type(cfg=cfg)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_conceptual: dict[str, torch.Tensor],\n",
    "        parameters: dict[str, torch.Tensor],\n",
    "        initial_states: dict[str, torch.Tensor] | None = None,\n",
    "    ) -> dict[str, torch.Tensor | dict[str, torch.Tensor]]:\n",
    "        \n",
    "        # initialize structures to store the information\n",
    "        states, out = self._initialize_information(conceptual_inputs=x_conceptual)\n",
    "\n",
    "        # initialize constants\n",
    "        batch_size, seq_length = x_conceptual[\"precipitation\"].shape\n",
    "        device = x_conceptual[\"precipitation\"].device\n",
    "\n",
    "        if initial_states is None:  # if we did not specify initial states it takes the default values\n",
    "            su = torch.full(\n",
    "                (batch_size, self.n_conceptual_models),\n",
    "                self._initial_states[\"su\"],\n",
    "                dtype=torch.float32,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "        else:  # we specify the initial states\n",
    "            su = initial_states[\"su\"]\n",
    "\n",
    "        # run hydrological model for each time step\n",
    "        for j in range(seq_length):\n",
    "            # Broadcast tensor to consider multiple conceptual models running in parallel\n",
    "            p = torch.tile(\n",
    "                x_conceptual[\"precipitation\"][:, j].unsqueeze(1),\n",
    "                (1, self.n_conceptual_models),\n",
    "            )\n",
    "            et = torch.tile(x_conceptual[\"pet\"][:, j].unsqueeze(1), (1, self.n_conceptual_models))\n",
    "\n",
    "            # 1 bucket reservoir ------------------\n",
    "            su = su + p  # [mm]\n",
    "            ret = et * parameters[\"ET_aux\"][:, j, :]  # [mm]\n",
    "            su = torch.maximum(torch.tensor(0.0, requires_grad=True, dtype=torch.float32), su - ret)  # [mm]\n",
    "            qi_out = su * parameters[\"ku\"][:, j, :]  # [mm]\n",
    "            su = su - qi_out  # [mm]\n",
    "\n",
    "            # states\n",
    "            states[\"su\"][:, j, :] = su\n",
    "\n",
    "            # discharge\n",
    "            out[:, j, 0] = torch.mean(qi_out, dim=1)  # [mm]\n",
    "\n",
    "        # last states\n",
    "        final_states = self._get_final_states(states=states)\n",
    "\n",
    "        return {\n",
    "            \"y_hat\": out,\n",
    "            \"parameters\": parameters,\n",
    "            \"internal_states\": states,\n",
    "            \"final_states\": final_states,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def _initial_states(self) -> dict[str, float]:\n",
    "        return getattr(self, '_initial_states_values', {\"su\": 0.001})\n",
    "\n",
    "    @_initial_states.setter\n",
    "    def _initial_states(self, value: dict[str, float]):\n",
    "        self._initial_states_values = value\n",
    "\n",
    "    @property\n",
    "    def parameter_ranges(self) -> dict[str, tuple[float, float]]:\n",
    "        return getattr(self, \"parameter_ranges_values\", {\"ku\": (0.002, 1.0), \"ET_aux\": (0.0, 1.5)})\n",
    "        \n",
    "    @parameter_ranges.setter\n",
    "    def parameter_ranges(self, value: dict[str, tuple[float, float]]):\n",
    "        self.parameter_ranges_values = value\n",
    "\n",
    "config = config._cfg\n",
    "config[\"conceptual_model\"] = \"custom_model\"\n",
    "config[\"dynamic_parameterization_conceptual_model\"] = [\"ku\", \"ET_aux\"]\n",
    "\n",
    "config = Config(config)\n",
    "config.dump()\n",
    "\n",
    "model.conceptual_model = my_model(cfg=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d55b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check conceptual model parameter ranges and types\n",
    "print(model.conceptual_model.parameter_ranges)\n",
    "print(model.conceptual_model.parameter_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6eac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model.load_state_dict(\n",
    "    torch.load(config.path_save_folder / \"model/model_epoch_04.pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc906684",
   "metadata": {},
   "source": [
    "### Part 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00592987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start trainer\n",
    "handler_training = Trainer(config, dataloaders, model)\n",
    "\n",
    "# Get list of learning rates\n",
    "num_epochs = config.epochs\n",
    "\n",
    "lrs = list(range(1, num_epochs + 1))\n",
    "lrs = [config.learning_rate[max(k for k in config.learning_rate if k <= num)] for num in lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training and report\n",
    "config.logger.info(\"Starting training\")\n",
    "config.logger.info(f\"{'':^5} | {'':^8} | {'Trainining':^30} | {'Validation':^30} |\")\n",
    "config.logger.info(f\"{'Epoch':^5} | {'LR':^8} | {'Loss':^8} | {'NSE':^8} | {'Time':^8} | {'Loss':^8} | {'NSE':^8} | {'Time':^8} |\")\n",
    "\n",
    "time_training = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # Set learning rate\n",
    "    handler_training.optimizer.update_optimizer_lr(epoch=(epoch + 1))\n",
    "\n",
    "    # Train\n",
    "    loss_train, nse_train, time_train = handler_training.run_epoch(\"training\")\n",
    "    if (epoch + 1) % config.validate_every != 0:\n",
    "        config.logger.info(f\"{epoch + 1:^5} | {lrs[epoch]:^8.1e} | {loss_train:^8.4f} | {nse_train:^8.4f} | {time_train:^8} | {'':^8} | {'':^8} | {'':^8} |\")\n",
    "        continue\n",
    "    \n",
    "    # Validate\n",
    "    loss_val, nse_val, time_val = handler_training.run_epoch(\"validation\")\n",
    "    config.logger.info(f\"{epoch + 1:^5} | {lrs[epoch]:^8.1e} | {loss_train:^8.4f} | {nse_train:^8.4f} | {time_train:^8} | {loss_val:^8.4f} | {nse_val:^8.4f} | {time_val:^8} |\")\n",
    "\n",
    "# Finish training\n",
    "time_training = str(datetime.timedelta(seconds=int(time.time() - time_training)))\n",
    "config.logger.info(\"Run completed successfully\")\n",
    "config.logger.info(f\"Total run time: {time_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6eb49",
   "metadata": {},
   "source": [
    "### Part 5. Postprocess model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler_postprocessing = Postprocessor(config)\n",
    "results = handler_postprocessing.postprocess(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909fd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29308591",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_id = \"73014\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 5))\n",
    "results.sel(basin=basin_id, last_n=365).y_obs.plot(ax=ax, label=\"Observed\", color=\"tab:blue\")\n",
    "results.sel(basin=basin_id, last_n=365).y_hat.plot(ax=ax, label=\"Predicted\", color=\"tab:orange\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-hybrid-models (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
